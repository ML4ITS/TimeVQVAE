dataset:
  in_channels: 1
  data_scaling: True
  batch_sizes:
    stage1: 64
    stage2: 32 #256  # 32 is the batch size used in c-TimeVQVAE
    stage3: 128
  num_workers: 0

exp_params:
  LR: 0.001
  weight_decay: 0.00001

trainer_params:
  # max_epochs:
  #   stage1: 2000
  #   stage2: 10000
    # stage3: 2000
  max_steps:
    stage1: 5000
    stage2: 100000
  val_check_interval:
    stage1: 500
    stage2: 10000

encoder:
  dim: 64
  n_resnet_blocks: 4
  downsampled_width:
    lf: 8
    hf: 32

decoder:
  dim: 64
  n_resnet_blocks: 4


VQ-VAE:
  n_fft: 8
  codebook_sizes:
    lf: 32
    hf: 32
  decay: 0.8
  commitment_weight: 1.
  codebook_dim: 64
  emb_dropout: 0.
  perceptual_loss_weight: 0


MaskGIT:
  choice_temperatures: # for masking
    lf: 4
    hf: 4
  stochastic_sampling: 1  # from (Lee et al., 2022)
  T: 10
  prior_model:
    hidden_dim: 256
    n_layers: 4
    heads: 2
    ff_mult: 1
    use_rmsnorm: True
    p_unconditional: 0.2
  ESS:
    use: False
    error_ratio_ma_rate: 0.3

class_guidance:
  guidance_scale: 1.

fidelity_enhancer:
  stochastic_sampling: 1  # temperature
  dim: 8
  dim_mults:
    - 1
    - 2
    - 4
    - 8
  resnet_block_groups: 4

evaluation:
  batch_size: 128
  min_num_gen_samples: 1024
  use_fidelity_enhancer: False